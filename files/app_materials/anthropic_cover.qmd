---
toc: false

format: pdf
editor: source

header-includes:
  - \usepackage{fontawesome5}
  - \usepackage{xcolor}
  - \definecolor{quarto-callout-color}{HTML}{909090}
  - \usepackage{fancyhdr}
  - \usepackage{graphicx}
  - \pagestyle{fancy}
  - \fancyhead[R]{ \includegraphics[width=1.7in]{DevLab_Logo_29Mar2023.png}}
  - \fancyhead[L]{}
  - \fancyhead[C]{}
  - \renewcommand{\headrulewidth}{0pt}
  - \usepackage[margin = 1in]{geometry} 
  - \addtolength{\topmargin}{0in}
  - \fancyfoot[C]{}
  - \renewcommand{\footrulewidth}{0pt}
  - \pagenumbering{gobble}
---

\begin{flushleft}
Jeremy Springman, PhD\\
Director of Research, PDRI-DevLab\\
Research Assistant Professor\\
University of Pennsylvania\\
\url{jrspringman.github.io}
\end{flushleft}

I am an applied researcher passionate about designing and conducting rigorous research to help stakeholders make better decisions in the real-world. As a Research Assistant Professor at the University of Pennsylvania and Director of Research at PDRI-DevLab, I have spent the last decade using causal inference and machine learning to inform high-stakes decision-making by policymakers in the U.S. government. From designing and analyzing complex experimental studies to delivering rigorous, data-driven insights that inform strategic decisions, I have the skills and experience to drive Anthropic's strategy to understand how AI products can best meet user needs. 

<!-- Partner with other teams -->
At UPenn, I manage a large portfolio of federally funded research projects. I have eight years of experience working with clients and stakeholders to identify high-impact research opportunities, partnering with other experts to design rigorous research, coordinating multiple stakeholders across countries and languages, and executing complicated research designs on sensitive topics with limited resources in challenging settings. Over the past six years, I have managed and mentored an interdisciplinary team of twelve researchers and data scientists. Since 2022, I have been awarded \$3.5 million as a principal investigator on both federal and private research grants, carrying projects from conceptualization and proposal through design, implementation, and the dissemination of results to the scientific and policy communities. 

As someone who has been using machine learning and AI in policy-focused governance research since 2019, I am deeply impressed by the seriousness of Anthropic’s efforts to engage on matters of scientific advancement, rare mental health conditions like schizophrenia, and national security.

My experience with AI began in 2019 when the first generation of open source transformer models were released. My team developed a data pipeline that scraped news from high-quality media outlets in emerging markets and fine-tuned RoBERTa models to monitor reporting on the occurrence of important political events. The data produced by this pipeline was fed to data dashboards that provided information to policymakers about when and where important events were occurring and provided quantitative forecasts of activity over the coming months. As AI has progressed, we have integrated increasingly sophisticated models to extract increasingly sophisticated types of information from this text, including the precise location of events, the number of high-quality sources being referenced within the article, and the types of actors involved. This background has given me unique insights into how decision-makers and ordinary users think about the capabilities and applications of AI systems.

My research portfolio is divided into two parts. The first portfolio focuses on causal inference research, including complex RCTs executed amidst government repression and civil war, large-scale surveys requiring both online and in-person data collection, and sophisticated survey experiments. The second focuses on computation social science, including machine learning, AI, big data collection, and forecasting. Building data pipelines and products to anticipate and communicate risk.

I have deep experience leading randomized experiments and causal inference projects commissioned by stakeholders to generate actionable insights. These projects have given me years of experience using advanced methods to address novel design and measurement challenges. I have designed and publicly pre-registered more than a dozen randomized experiments using bespoke simulation-based power calculations. I have also leveraged tools like non-bipartite matching, matched-group randomization, and re-randomization to extract maximum statistical precision from small and high variance samples and deployed sophisticated approaches to adjust for multiple-hypothesis testing, including Bayesian regularization. I have also designed trials to deal with the reality of social networks by collecting and using network data to estimate the size of treatment spillovers through network connections.

In addition to generating academic publications and contributing to our theoretical understanding of the social world, my research has directly informed policy. As a research associate at Duke University, I led an evaluation that provided rigorous evidence that a U.S. government foreign aid program was failing to accomplish it's goals, resulting in the program's cancellation and a more effective use of government resources. 

In another project, I worked with policymakers at the U.S. Agency for International Development to design a conjoint survey experiment that answered pressing questions about the strategic behavior of non-profits receiving U.S. support in highly repressive countries. Based on the findings, I produced a policy brief recommending changes to how the agency supports local partners in repressive countries and presented the recommendations to high-level officials. A third project used insights from behavioral psychology and economics to design and evaluate an intervention to increase civic engagement and social cohesion among youth in highly polarized countries. This resulted in a highly effective intervention that my partners are seeking to scale across developing countries.

I also have extensive background in machine learning research. As a post-doctoral research associate, I co-founded the Machine Learning for Peace (ML4P) project, a high-profile project to build a public-facing early warning system forecasting political instability in emerging markets. Under ML4P, we have built a curated repository of 200+ million articles collected from nearly 400 high-quality domestic news outlets publishing in more than 40 languages across 63 developing countries. Our capture from these local sources is much more comprehensive than other big data media repositories and our composition is much more stable and multi-lingual than proprietary sources like LexisNexis. 

My lab used data from this project publish more than a dozen commissioned policy reports, develop public-facing data dashboards averaging 150 hours of monthly active usage time by decision-makers, and attracted 1,200 unique users from 70 countries over a 10 month period, with more than 800 policymakers signing up to receive our monthly reports. The success of this project led to my promotion to Research Assistant Professor, where I manage three full-time data scientists, five pre-doctoral fellows, multiple affiliated faculty and PhD students, and a large pool of undergraduates. 

I am passionate about translating scientific research into action, and have given invited talks to hundreds of policymakers across more than a dozen agencies in five countries. I specialize in communicating technical material to non-technical audiences: from policy officials at the U.S. Department of State to civil society stakeholders across emerging markets, I have built a track record of translating complex analyses into clear, strategic recommendations. 

<!-- I have deep technical proficiency in statistical programming (R and Python), document preparation and visualization (markdown, Quarto, and Shiny), version control (git, GitHub, and renv), programming online surveys (Javascript and html), and have managed teams using high-performance computing environments, NoSQL document-stage databases, and core machine learning Python libraries (scikit-learn, XGBoost, LightGBM, PyTorch, Optuna). I'm excited to deploy these skills in the technology sector, where analytics can inform decisions at an even faster pace. -->

<!-- Working at a university has also given the opportunity to teach and mentor students at the undergraduate and graduate level. My academic career has taught me the importance of mentorship, and I plan to continue fostering data science best practices by guiding junior colleagues and building a collaborative culture that values creativity and rigor.  -->

I admire Anthropic’s culture of thinking deeply about how to conceptualize the potential risks of increasingly capable AI systems, measure the potential realization of these risk under different model development scenarios, and weigh these risks against the massive potential for AI to improve human life. I fully recognize that the opportunity to work with Anthropic to guide the advancement of one of humankind's most important technologies would be a tremendous privilege.  
