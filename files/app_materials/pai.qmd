---
toc: false

format: pdf
editor: source

header-includes:
  - \usepackage{fontawesome5}
  - \usepackage{xcolor}
  - \definecolor{quarto-callout-color}{HTML}{909090}
  - \usepackage{fancyhdr}
  - \usepackage{graphicx}
  - \pagestyle{fancy}
  - \fancyhead[R]{ \includegraphics[width=1.7in]{DevLab_Logo_29Mar2023.png}}
  - \fancyhead[L]{}
  - \fancyhead[C]{}
  - \renewcommand{\headrulewidth}{0pt}
  - \usepackage[margin = 1in]{geometry} 
  - \addtolength{\topmargin}{0in}
  - \fancyfoot[C]{}
  - \renewcommand{\footrulewidth}{0pt}
  - \pagenumbering{gobble}
---

\begin{flushleft}
Jeremy Springman, PhD\\
Director of Research, PDRI-DevLab\\
Research Assistant Professor\\
University of Pennsylvania\\
\url{jrspringman.github.io}
\end{flushleft}

As a Research Assistant Professor at the University of Pennsylvania and Director of Research in a large social science research lab, I have spent the last decade using causal inference and machine learning to inform high-stakes decision-making by policymakers in the U.S. government. Since the emergence of BERT in 2019, AI tools have been fundamental to my research. After successfully leading more than a dozen large-scale research projects commissioned by federal agencies on topics ranging from planning around geopolitical risks to the optimal design of awards and contracts, I want to play a more direct role in the evolution and understanding of the most important general purpose technology of my generation.

My experience with AI began in 2019 when the first generation of open source BERT models were released. As a post-doctoral research associate, I co-founded a high-profile project to build a public-facing early warning system forecasting political instability in emerging markets. Managing a team of data scientists and PhD students, I led the construction of a research infrastructure to continually update a large, highly multilingual corpus of high-quality media and use deep learning translation models and fine-tuned transformers and LLMs to extract information from text. This project's funding was renewed over six years and attracted support from the U.S. Department of Defense, Agency for International Development, and private donors. As AI has progressed, we have integrated increasingly sophisticated models to extract increasingly sophisticated types of information from this text, including the precise location of events, the number of high-quality sources being referenced within the article, and the types of actors involved.

As an applied researcher, one of my primary responsibilities has been to communicate about our data to high-level policymakers and stakeholders that use our event monitoring and forecasting to inform their decision-making. It has been fascinating to watch the evolution of how non-technical decision makers regard AI between 2019 and 2025. At the beginning of my work, our use of transformer models to extract information about political events from text was often met with intense skepticism, and I had to focus my communications on providing clear, compelling examples to illustrate the surprising ability of these models. By 2024, many of our stakeholders had become extremely receptive and often overly optimistic about what current AI could accomplish.

I admire Partnership on AIâ€™s culture of thinking deeply about how to conceptualize the potential risks of increasingly capable AI systems, measure the potential realization of these risk under different model development scenarios, and weigh these risks against the massive potential for AI to improve human life. My experience both using AI for policy research and communicating about AI with policymakers makes me a great candidate for this position.

I also have deep experience leading randomized experiments and causal inference projects commissioned by stakeholders to generate actionable insights. These projects have given me years of experience using advanced methods to address novel design and measurement challenges. I have designed and publicly pre-registered more than a dozen randomized experiments using bespoke simulation-based power calculations. I have also leveraged tools like non-bipartite matching, matched-group randomization, and re-randomization to extract maximum statistical precision from small and high variance samples and deployed sophisticated approaches to adjust for multiple-hypothesis testing, including Bayesian regularization. I have also designed trials to deal with the reality of social networks by collecting and using network data to estimate the size of treatment spillovers through network connections.

In addition to generating academic publications and contributing to our theoretical understanding of the social world, my research has directly informed policy. As a research associate at Duke University, I led an evaluation that provided rigorous evidence that a U.S. government foreign aid program was failing to accomplish it's goals, resulting in the program's cancellation and a more effective use of government resources.

In another project, I worked with policymakers at the U.S. Agency for International Development to design a conjoint survey experiment that answered pressing questions about the strategic behavior of non-profits receiving U.S. support in highly repressive countries. Based on the findings, I produced a policy brief recommending changes to how the agency supports local partners in repressive countries and presented the recommendations to high-level officials. A third project used insights from behavioral psychology and economics to design and evaluate an intervention to increase civic engagement and social cohesion among youth in highly polarized countries. This resulted in a highly effective intervention that my partners are seeking to scale across developing countries.

You can find some examples of my writing [on my wesbite](https://jrspringman.github.io/research.html). Thank you for your time and consideration.
